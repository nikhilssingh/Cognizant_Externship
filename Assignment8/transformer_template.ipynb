{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c7d2897",
   "metadata": {},
   "source": [
    "# Transformer Text Generation\n",
    "\n",
    "In this notebook, we will explore how transformer models (like GPT-2) can generate text based on a given prompt. We will experiment with generating text by adjusting parameters like temperature and sequence length.\n",
    "\n",
    "## Instructions\n",
    "1. Change the prompt below to experiment with different types of text generation.\n",
    "2. Adjust the `max_length` and `temperature` parameters to see how they affect the output.\n",
    "3. Generate at least 3 samples with different prompts and compare the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbce095",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nikhil Singh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Device set to use cpu\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the future, education will become increasingly important for young people.\n",
      "\n",
      "\"It is our hope that the government will make education a priority. We hope that it will be a platform for students to achieve their full potential,\" he told Fairfax Media.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load GPT-2 text generation model\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "\n",
    "# Set your prompt\n",
    "prompt = 'In the future, education will' \n",
    "\n",
    "# Generate text\n",
    "result = generator(prompt, max_length=50, temperature=0.7)\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69a033d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The impact of AI on the future of work, says Eirik JÃ¤rvinsson at the University of Helsinki in Finland. \"We can imagine that people are more aware and more sophisticated in the future, and that people will use better analytical\n",
      "Once upon a time, there was a kingdom of the gods, and a kingdom of the gods, and a kingdom of the gods, and a kingdom of the gods.\n",
      "\n",
      "In the last days, there was a kingdom of the gods, and a kingdom of the gods, and a kingdom of the gods, and a kingdom of the gods, and a kingdom of the gods, and a kingdom of the gods, and a kingdom of the gods, and a kingdom of the gods, and a\n"
     ]
    }
   ],
   "source": [
    "# Experiment with different prompts\n",
    "prompt = 'The impact of AI on the future of work'\n",
    "result = generator(prompt, max_length=50, temperature=0.8)\n",
    "print(result[0]['generated_text'])\n",
    "prompt = 'Once upon a time, there was a kingdom'\n",
    "result = generator(prompt, max_length=100, temperature=0.6)\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0d0d32",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "\n",
    "Now that you have experimented with text generation, write a brief report on your observations.\n",
    "\n",
    "1. What patterns did you notice in the generated text?\n",
    "2. How did changing the temperature affect the creativity and coherence of the text?\n",
    "3. What types of prompts yielded the most coherent results?\n",
    "4. What are the limitations of GPT-2 based on your experimentation?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
